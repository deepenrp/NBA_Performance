{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from operator import itemgetter\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_stats(year):\n",
    "    \n",
    "    adv_url = \"https://www.basketball-reference.com/leagues/NBA_{}_advanced.html\".format(year)\n",
    "    adv_html = urlopen(adv_url)\n",
    "    soup_adv = BeautifulSoup(adv_html)\n",
    "    \n",
    "    pg_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\".format(year)\n",
    "    pg_html = urlopen(pg_url)\n",
    "    soup_pg = BeautifulSoup(pg_html)\n",
    "    \n",
    "    # To see the column headers we have\n",
    "    soup_adv.findAll('tr', limit=2)\n",
    "    # GetText() function will help extract the text from the data we need into a list format\n",
    "    headers_adv = [th.getText() for th in soup_adv.findAll('tr', limit=2)[0].findAll('th')]\n",
    "    # Exclude the first column to remove ranking of the players from the webpage\n",
    "    headers_adv = headers_adv[1:]\n",
    "    headers_adv\n",
    "    \n",
    "    # To see the column headers we have\n",
    "    soup_pg.findAll('tr', limit=2)\n",
    "    # GetText() function will help extract the text from the data we need into a list format\n",
    "    headers_pg = [th.getText() for th in soup_pg.findAll('tr', limit=2)[0].findAll('th')]\n",
    "    # Exclude the first column to remove ranking of the players from the webpage\n",
    "    headers_pg = headers_pg[1:]\n",
    "    headers_pg\n",
    "    \n",
    "    # Remove the first header row\n",
    "    rows_adv = soup_adv.findAll('tr')[1:]\n",
    "    player_stats_adv = [[td.getText() for td in rows_adv[i].findAll('td')]\n",
    "                for i in range(len(rows_adv))]\n",
    "\n",
    "    # Remove the first header row\n",
    "    rows_pg = soup_pg.findAll('tr')[1:]\n",
    "    player_stats_pg = [[td.getText() for td in rows_pg[i].findAll('td')]\n",
    "                for i in range(len(rows_pg))]\n",
    "\n",
    "    # Year's Player per game stats\n",
    "    stats_year_pg = pd.DataFrame(player_stats_pg, columns = headers_pg)\n",
    "\n",
    "    # Use notnull() function to find the non-missing values, when there are missing values in the dataframe.\n",
    "    stats_year_pg = stats_year_pg[stats_year_pg['Player'].notnull()]\n",
    "\n",
    "    # stats_2010_pg.drop(stats_2010_pg.index[0])\n",
    "\n",
    "    # Convert string/object to float\n",
    "    cols = ['Age', 'G', 'GS','MP', 'FG','3P','FT%','FG%', '3P%','AST', 'STL', 'BLK','TRB', 'PTS','eFG%']\n",
    "    stats_year_pg[cols] = stats_year_pg[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "    # Replacing na values to 0\n",
    "    stats_year_pg = stats_year_pg[:].fillna(0)\n",
    "\n",
    "    # # Keep the first record in the dataset\n",
    "    # stats_year_pg = stats_year_pg.drop_duplicates(['Player'], keep = 'first')\n",
    "\n",
    "    # Year Player advanced stats\n",
    "    stats_year_adv = pd.DataFrame(player_stats_adv, columns = headers_adv)\n",
    "\n",
    "    # Use notnull() function to find the non-missing values, when there are missing values in the dataframe.\n",
    "    stats_year_adv = stats_year_adv[stats_year_adv['Player'].notnull()]\n",
    "\n",
    "    # stats_year_pg.drop(stats_year_pg.index[0])\n",
    "\n",
    "    # Convert string/object to float\n",
    "    cols = ['Age', 'G', 'TRB%','AST%','STL%','BLK%','PER','TS%', 'WS','USG%','BPM','VORP']\n",
    "    stats_year_adv[cols] = stats_year_adv[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "    # Replacing na values to 0\n",
    "    stats_year_adv = stats_year_adv[:].fillna(0)\n",
    "\n",
    "    # # Keep the first record in the dataset\n",
    "    # stats_year_adv = stats_year_adv.drop_duplicates(['Player'], keep = 'first')\n",
    "    \n",
    "    # Merge both per game and advanced stats\n",
    "    merged_year_stats = pd.merge(stats_year_pg, stats_year_adv, on=['Player','Tm'], how='outer')\n",
    "\n",
    "    # Save the datasets\n",
    "\n",
    "    stats_year = \"season\" + \"_\" + str(year) + \"_\" + \"stats\"\n",
    "\n",
    "    merged_year_stats.to_csv(str(stats_year) + \".csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2015, 2016, 2017, 2018, 2019]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of Years to scrape data\n",
    "years = list(range(2015, 2020))\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    season_stats(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
